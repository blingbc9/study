재현율 : 실재 일어난 일중 , 내가 맞춘 것 (= 민감도) recall
정확도 : 내가 예상한 것 중 맞춘 것 Presision
F1 score :  2* (Presision * Recall / Presision + Recall  )

특이도 : 발생하지 않은 일들 중, 아닐 거라 예상한 것 Specificity Specificity
-----------------------------------------------------------------------------------
p.390
ROCR Curve 
- 2진 분류(binary classfication)  성능평에가 많이 사용됨
- 그래프가 왼쪽에 가까울 수록 올바르게 예측한 비율이 높다
- 그래프가 왼쪽에 가까울 수록 올바르게 예측한 비율이 높다
-ROC 곡선 하단의 면적을 AUROC(Area Under ROC)라고 한다.
AUROC의 면적이 클 수록 (1에 가까울수록) 모형의 성능이 좋다고 평가한다.


가로축 FPR(1-특이도(Specificity))
- 1인 케이스에 대해 1로 예측한 것(내가 맞춘 것)
세로축 TPR()
- 0인 케이스에 대해 1로 잘못 예측한 것
-----------------------------------------------------------------------------------
P 393
* 이익도표
- 분류모형 성능평가를 위한 척도

- 관측치에 대한 예측확률을 내림차순으로 정렬
- 데이터를 10개의 구간으로 나눈 뒤 반응률(response)을 산출 
- 기본향상도(baselin lift) 에 비해 반응률이 몇배나 높은지 계산, 이것을 향상도(lift)라 함
- 상위 등급일수록 높은 반응률(response),  향상도(lift)가 빠른 속도록 감소한다.
- 등급별로 향상도가 급격하게 변동할수록 좋은 모형, 향상도가 들쭉날쭉하면 안좋은 모형
-----------------------------------------------------------------------------------
P 395
데이터 마이닝 방법론
	분류분석
		로지스틱회귀분석, 의사결정나무, 베이지안 분류, 인공신경망, SVM
		의사결정나무 : 성과를 한 눈에 볼 수 있음,
		
		
	클러스터링
	회귀분석

분류분석
- 데이터가 어떤 '그룹'에 속하는지 예측
- 클러스터링과 유사 BUT 분류분석은 각 그룹이 정의되어 있다.
- 지도학습

예측분석
- 시계열분석처럼 시간에 따른 값 두 개만을 이용
- 한 개의 설명변수

분류와 예측의 차이
분류 : 레코드(튜플)의 범주형 속성값을 맞힘
예측 : 레코드(튜플)의 연속형 속성값을 맞힘

분류기법
- 회귀분석, 로지스틱 회귀분석
- 의사결정나무
- 베이지안 분류
- 인공신경망
- 지지도벡터기계 support vector machine
- k 최근접 이웃
- 규칙기반의 분류, 사례기반추론

p 397
로지스틱 회귀분석
- 반응변수가 범주형인 경우
- 예측변수가 주어질 때, 반응변수가 각 범주에 속할 확률이 얼마인지 추정, 추정확률을 기준치에 따라 분류하는 목적

오즈비, 오즈
오즈 : 성공할 확률이 실패할 확률의 몇 배인지 나나태는 확률,

선형회귀분석, 로지스틱회귀분석의 차이

선형회귀분석 
- 종속변수 : 연속형 변수
- 계수 추정법 : 최소제곱법
- 모형검정 : F-검정, T-검정

로지스틱 회귀분석
- 종속변수 : (0,1)
- 계수 추정법 : 최대우도추정법
- 모형 검정 : 카이제곱 검정(x**-test)

p 400
 의사결정나무
-입력값에 대하여 출력값을 예측하는 모형

예측력과 해석력
- 고객의 유치방안을 예측하고자 하는 경우 예측력에 치중
- 신용평가 심사시, 부적격 사유를 설명해야하므로 해석력에 치중

활용
1) 세분화 :  비슷한 특성을 갖는 그룹으로 분할, 특성을 파악
2) 분류 :  예측변수에 근거해 목표변수 범주를 몇 개의 등급으로 분류
3) 예측 : 규칙을 찾아내고 이를 기반으로 예측
4) 차원축소, 변수선택 :  
5) 교호작용효과
	- 여러 개의 예측변수들을 결합하여 목표변수에 작용하는 규칙을 파악
	- 범주의 병합, 연속형 변수의 이산화

장점
- 한 변수와 상관성이 높은 불필요한 변수가 있어도 영향을 받지 않는다
- 설명변수나 목표변수에 수치형변수와 범주형변수 모두 사용 가능

단점
- 새로운 자료에 대한 과대적합 가능성
- 분류 경계선 부근의 자료값에 대해 오차가 큼
- 설명 변수 간의 중요도를 판단하기 어려움

분리규칙
- 최적 분할 결정은, 불순도 감소량을 가장 크게하는 분할

분리기준
	이산형 목표변수: 카이제콥 통계량 p값, 지니지수, 엔트로피 지수
	연속형 목표변수: 분산분석에서 F통계량, 분산의 감소량

분순도의 측도
- 카이제콥 통계량: ((실제도수 - 기대도수)**/기대도수)의 합
- 지니지수 :노드의 불순도를 나타내는 값
	 지니지수가 클수록, 이질적이다, 순수도가 낮다
- 엔트로피 지수 : 무질서 정도에 대한 측도, 값이 클수록 순수도가 낮다

의사결정나무 알고리즘
CART : 
	목표변수가 범주형일 경우, 지니지수/ 연속형일 경우 분산을 이용한 이진분리
C4.5, C5.0
- 엔트로피지수(무질서 정도)활용

CHAID(CHI-squared Automatic Interaction Detection)
- 범주형 변수
- 카이제콥 통계량 사용
	